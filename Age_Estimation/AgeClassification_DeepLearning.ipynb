{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age Classification\n",
    "In this project,we are implementing age classification using MobileNet.\n",
    "\n",
    "## Data\n",
    "We will be using the IMDB Wiki dataset (https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/) for this project. We have already cleaned up the dataset to remove the non-face images as well as images with erroneous ages (age > 100 or age < 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "We have used the output layer of MobileNet as the base model. Then we have added three fully connected layers and a dropout layer. Since we have ages between 1 to 99, last layer will have 99 nodes. We have used softmax activation function to classify the age between the 99 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tf_env/lib/python3.6/site-packages/keras_applications/mobilenet.py:208: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    }
   ],
   "source": [
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dropout(0.5)(x)\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(99,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "We are freezing first 20 layers in the network and we will train the subsequent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "#now a model has been created based on our architecture\n",
    "# set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from measuring the classification loss, we will also measure the mean absolute error in prediction of the age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_mae(y_true, y_pred):\n",
    "    true_age = K.sum(y_true * K.arange(1, 100, dtype=\"float32\"), axis=-1)\n",
    "    pred_age = K.sum(y_pred * K.arange(1, 100, dtype=\"float32\"), axis=-1)\n",
    "    mae = K.mean(K.abs(true_age - pred_age))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "Let's create a data generator that loads the image, class pairs from our trainig data directory. We will also set up the loss function and the optimizer for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131003 images belonging to 99 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory('imdb_classes/train/',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=[age_mae])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-stage2-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "step_size_train=train_generator.n//train_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add a data generator for our validation data and run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43624 images belonging to 99 classes.\n",
      "Epoch 1/10\n",
      "4093/4093 [==============================] - 1448s 354ms/step - loss: 3.1082 - age_mae: 5.4260 - val_loss: 3.5256 - val_age_mae: 7.1250\n",
      "Epoch 2/10\n",
      "4093/4093 [==============================] - 1439s 352ms/step - loss: 3.0437 - age_mae: 5.1479 - val_loss: 3.5054 - val_age_mae: 7.0546\n",
      "Epoch 3/10\n",
      "4093/4093 [==============================] - 1423s 348ms/step - loss: 2.9865 - age_mae: 4.9535 - val_loss: 3.5760 - val_age_mae: 7.3682\n",
      "Epoch 4/10\n",
      "4093/4093 [==============================] - 1452s 355ms/step - loss: 2.9242 - age_mae: 4.7499 - val_loss: 3.6316 - val_age_mae: 7.6298\n",
      "Epoch 5/10\n",
      "4093/4093 [==============================] - 1454s 355ms/step - loss: 2.8745 - age_mae: 4.5896 - val_loss: 3.6783 - val_age_mae: 7.3103\n",
      "Epoch 6/10\n",
      "4093/4093 [==============================] - 1429s 349ms/step - loss: 2.8262 - age_mae: 4.4561 - val_loss: 3.6986 - val_age_mae: 7.2361\n",
      "Epoch 7/10\n",
      "4093/4093 [==============================] - 1417s 346ms/step - loss: 2.7794 - age_mae: 4.3183 - val_loss: 3.7337 - val_age_mae: 7.2833\n",
      "Epoch 8/10\n",
      "4093/4093 [==============================] - 1427s 349ms/step - loss: 2.7380 - age_mae: 4.2009 - val_loss: 3.8058 - val_age_mae: 7.1767\n",
      "Epoch 9/10\n",
      "4093/4093 [==============================] - 1439s 352ms/step - loss: 2.6984 - age_mae: 4.1133 - val_loss: 3.8119 - val_age_mae: 7.1908\n",
      "Epoch 10/10\n",
      "4093/4093 [==============================] - 1431s 350ms/step - loss: 2.6622 - age_mae: 4.0093 - val_loss: 3.8677 - val_age_mae: 7.3835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3e4653a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory('imdb_classes/val/',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "step_size_val=val_generator.n//val_generator.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    validation_steps=step_size_val,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "So we can see that we are able to achieve a better mean absolute error (7.3 years) with this simple neural network than what we could get with our SVM using LBP features (mae = 10 years)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
